{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65796d96af964633ab5dd00e24bf947f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/6.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\samue\\.cache\\huggingface\\hub\\datasets--yelp_review_full. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff07be06fb948ed9a0bc5990abe1590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/299M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e4a5c5e85c4781a04b16add8546e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/23.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64650a3194dc4ca7a74fd5a0a7168eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/650000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c868495483ee4229ac2185b9091c66ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset=load_dataset(\"yelp_review_full\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 4, 'text': \"dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\"}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e76c291fc0e4748828c30718ebdd173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\samue\\.cache\\huggingface\\hub\\models--google-bert--bert-base-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea97671e8a84df39f4b9dc5a2e88ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014649dc6ffb4b828983b94d7432e051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215399b4cd6a4ab2a17f26016e8c5c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f60485ba1742c7ba41247b8832f7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/650000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e962aad709d14469a541995d9448f27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 4,\n",
       " 'text': \"dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\",\n",
       " 'input_ids': [101,\n",
       "  173,\n",
       "  1197,\n",
       "  119,\n",
       "  2284,\n",
       "  2953,\n",
       "  3272,\n",
       "  1917,\n",
       "  178,\n",
       "  1440,\n",
       "  1111,\n",
       "  1107,\n",
       "  170,\n",
       "  1704,\n",
       "  22351,\n",
       "  119,\n",
       "  1119,\n",
       "  112,\n",
       "  188,\n",
       "  3505,\n",
       "  1105,\n",
       "  3123,\n",
       "  1106,\n",
       "  2037,\n",
       "  1106,\n",
       "  1443,\n",
       "  1217,\n",
       "  10063,\n",
       "  4404,\n",
       "  132,\n",
       "  1119,\n",
       "  112,\n",
       "  188,\n",
       "  1579,\n",
       "  1113,\n",
       "  1159,\n",
       "  1107,\n",
       "  3195,\n",
       "  1117,\n",
       "  4420,\n",
       "  132,\n",
       "  1119,\n",
       "  112,\n",
       "  188,\n",
       "  6559,\n",
       "  1114,\n",
       "  170,\n",
       "  1499,\n",
       "  118,\n",
       "  23555,\n",
       "  2704,\n",
       "  113,\n",
       "  183,\n",
       "  9379,\n",
       "  114,\n",
       "  1134,\n",
       "  1139,\n",
       "  2153,\n",
       "  1138,\n",
       "  3716,\n",
       "  1106,\n",
       "  1143,\n",
       "  1110,\n",
       "  1304,\n",
       "  1696,\n",
       "  1107,\n",
       "  1692,\n",
       "  1380,\n",
       "  5940,\n",
       "  1105,\n",
       "  1128,\n",
       "  1444,\n",
       "  6059,\n",
       "  132,\n",
       "  1105,\n",
       "  1128,\n",
       "  1169,\n",
       "  1243,\n",
       "  5991,\n",
       "  16179,\n",
       "  1106,\n",
       "  1267,\n",
       "  18137,\n",
       "  1443,\n",
       "  1515,\n",
       "  1106,\n",
       "  1267,\n",
       "  1140,\n",
       "  1148,\n",
       "  119,\n",
       "  1541,\n",
       "  117,\n",
       "  1184,\n",
       "  1167,\n",
       "  1202,\n",
       "  1128,\n",
       "  1444,\n",
       "  136,\n",
       "  178,\n",
       "  112,\n",
       "  182,\n",
       "  2807,\n",
       "  1303,\n",
       "  1774,\n",
       "  1106,\n",
       "  1341,\n",
       "  1104,\n",
       "  1251,\n",
       "  11344,\n",
       "  178,\n",
       "  1138,\n",
       "  1164,\n",
       "  1140,\n",
       "  117,\n",
       "  1133,\n",
       "  178,\n",
       "  112,\n",
       "  182,\n",
       "  1541,\n",
       "  4619,\n",
       "  170,\n",
       "  9153,\n",
       "  119,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5bb166003fb4bdb98d085686cb9a3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Model Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", logging_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490874ef54db40c6a349360d4843d558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.6290825605392456,\n",
       " 'eval_model_preparation_time': 0.0015,\n",
       " 'eval_accuracy': 0.196,\n",
       " 'eval_runtime': 893.8143,\n",
       " 'eval_samples_per_second': 1.119,\n",
       " 'eval_steps_per_second': 0.14}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f9c146876b465b9e36b645b30f86e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6909, 'grad_norm': 10.719744682312012, 'learning_rate': 4.933333333333334e-05, 'epoch': 0.04}\n",
      "{'loss': 1.6032, 'grad_norm': 11.602723121643066, 'learning_rate': 4.866666666666667e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7458, 'grad_norm': 11.82161808013916, 'learning_rate': 4.8e-05, 'epoch': 0.12}\n",
      "{'loss': 1.6001, 'grad_norm': 8.613147735595703, 'learning_rate': 4.7333333333333336e-05, 'epoch': 0.16}\n",
      "{'loss': 1.671, 'grad_norm': 9.226383209228516, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.2}\n",
      "{'loss': 1.6995, 'grad_norm': 9.154727935791016, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.24}\n",
      "{'loss': 1.6298, 'grad_norm': 8.690225601196289, 'learning_rate': 4.5333333333333335e-05, 'epoch': 0.28}\n",
      "{'loss': 1.573, 'grad_norm': 9.406646728515625, 'learning_rate': 4.466666666666667e-05, 'epoch': 0.32}\n",
      "{'loss': 1.5245, 'grad_norm': 6.542826175689697, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.36}\n",
      "{'loss': 1.5254, 'grad_norm': 8.28404426574707, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.4}\n",
      "{'loss': 1.371, 'grad_norm': 10.143083572387695, 'learning_rate': 4.266666666666667e-05, 'epoch': 0.44}\n",
      "{'loss': 1.3756, 'grad_norm': 7.982404708862305, 'learning_rate': 4.2e-05, 'epoch': 0.48}\n",
      "{'loss': 1.4283, 'grad_norm': 7.017925262451172, 'learning_rate': 4.133333333333333e-05, 'epoch': 0.52}\n",
      "{'loss': 1.1486, 'grad_norm': 10.05012321472168, 'learning_rate': 4.066666666666667e-05, 'epoch': 0.56}\n",
      "{'loss': 1.1158, 'grad_norm': 15.632146835327148, 'learning_rate': 4e-05, 'epoch': 0.6}\n",
      "{'loss': 1.4913, 'grad_norm': 32.96185302734375, 'learning_rate': 3.933333333333333e-05, 'epoch': 0.64}\n",
      "{'loss': 1.4617, 'grad_norm': 7.088161945343018, 'learning_rate': 3.866666666666667e-05, 'epoch': 0.68}\n",
      "{'loss': 1.4184, 'grad_norm': 32.1922721862793, 'learning_rate': 3.8e-05, 'epoch': 0.72}\n",
      "{'loss': 1.3108, 'grad_norm': 9.775577545166016, 'learning_rate': 3.733333333333334e-05, 'epoch': 0.76}\n",
      "{'loss': 1.306, 'grad_norm': 12.567358016967773, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.8}\n",
      "{'loss': 1.3483, 'grad_norm': 12.423315048217773, 'learning_rate': 3.6e-05, 'epoch': 0.84}\n",
      "{'loss': 1.5819, 'grad_norm': 17.61754608154297, 'learning_rate': 3.5333333333333336e-05, 'epoch': 0.88}\n",
      "{'loss': 1.3271, 'grad_norm': 11.141088485717773, 'learning_rate': 3.466666666666667e-05, 'epoch': 0.92}\n",
      "{'loss': 1.2696, 'grad_norm': 6.650016784667969, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.96}\n",
      "{'loss': 1.3168, 'grad_norm': 12.06214714050293, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n",
      "{'loss': 1.2059, 'grad_norm': 15.641843795776367, 'learning_rate': 3.266666666666667e-05, 'epoch': 1.04}\n",
      "{'loss': 1.1322, 'grad_norm': 9.511832237243652, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.08}\n",
      "{'loss': 1.1685, 'grad_norm': 15.718693733215332, 'learning_rate': 3.1333333333333334e-05, 'epoch': 1.12}\n",
      "{'loss': 0.9939, 'grad_norm': 10.68175220489502, 'learning_rate': 3.066666666666667e-05, 'epoch': 1.16}\n",
      "{'loss': 1.0885, 'grad_norm': 12.867351531982422, 'learning_rate': 3e-05, 'epoch': 1.2}\n",
      "{'loss': 1.0954, 'grad_norm': 10.646446228027344, 'learning_rate': 2.9333333333333336e-05, 'epoch': 1.24}\n",
      "{'loss': 0.9561, 'grad_norm': 12.086124420166016, 'learning_rate': 2.8666666666666668e-05, 'epoch': 1.28}\n",
      "{'loss': 0.9707, 'grad_norm': 7.692249774932861, 'learning_rate': 2.8000000000000003e-05, 'epoch': 1.32}\n",
      "{'loss': 0.982, 'grad_norm': 8.896380424499512, 'learning_rate': 2.733333333333333e-05, 'epoch': 1.36}\n",
      "{'loss': 1.114, 'grad_norm': 8.362059593200684, 'learning_rate': 2.6666666666666667e-05, 'epoch': 1.4}\n",
      "{'loss': 0.9442, 'grad_norm': 14.42679214477539, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.44}\n",
      "{'loss': 1.1432, 'grad_norm': 9.156448364257812, 'learning_rate': 2.5333333333333337e-05, 'epoch': 1.48}\n",
      "{'loss': 1.0125, 'grad_norm': 11.301398277282715, 'learning_rate': 2.466666666666667e-05, 'epoch': 1.52}\n",
      "{'loss': 1.0713, 'grad_norm': 6.379336357116699, 'learning_rate': 2.4e-05, 'epoch': 1.56}\n",
      "{'loss': 1.2067, 'grad_norm': 18.40704345703125, 'learning_rate': 2.3333333333333336e-05, 'epoch': 1.6}\n",
      "{'loss': 0.9307, 'grad_norm': 10.996781349182129, 'learning_rate': 2.2666666666666668e-05, 'epoch': 1.64}\n",
      "{'loss': 1.0815, 'grad_norm': 8.140640258789062, 'learning_rate': 2.2000000000000003e-05, 'epoch': 1.68}\n",
      "{'loss': 1.0168, 'grad_norm': 21.67298126220703, 'learning_rate': 2.1333333333333335e-05, 'epoch': 1.72}\n",
      "{'loss': 1.2165, 'grad_norm': 11.41153621673584, 'learning_rate': 2.0666666666666666e-05, 'epoch': 1.76}\n",
      "{'loss': 0.9157, 'grad_norm': 8.113213539123535, 'learning_rate': 2e-05, 'epoch': 1.8}\n",
      "{'loss': 0.79, 'grad_norm': 6.649427890777588, 'learning_rate': 1.9333333333333333e-05, 'epoch': 1.84}\n",
      "{'loss': 1.0002, 'grad_norm': 12.366739273071289, 'learning_rate': 1.866666666666667e-05, 'epoch': 1.88}\n",
      "{'loss': 0.7884, 'grad_norm': 8.809772491455078, 'learning_rate': 1.8e-05, 'epoch': 1.92}\n",
      "{'loss': 0.8954, 'grad_norm': 9.8073091506958, 'learning_rate': 1.7333333333333336e-05, 'epoch': 1.96}\n",
      "{'loss': 0.9715, 'grad_norm': 7.544814109802246, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n",
      "{'loss': 0.7167, 'grad_norm': 14.949334144592285, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.04}\n",
      "{'loss': 0.8603, 'grad_norm': 7.0669074058532715, 'learning_rate': 1.5333333333333334e-05, 'epoch': 2.08}\n",
      "{'loss': 0.7756, 'grad_norm': 20.54330825805664, 'learning_rate': 1.4666666666666668e-05, 'epoch': 2.12}\n",
      "{'loss': 0.6638, 'grad_norm': 11.872383117675781, 'learning_rate': 1.4000000000000001e-05, 'epoch': 2.16}\n",
      "{'loss': 0.8089, 'grad_norm': 6.939366340637207, 'learning_rate': 1.3333333333333333e-05, 'epoch': 2.2}\n",
      "{'loss': 0.7843, 'grad_norm': 10.478065490722656, 'learning_rate': 1.2666666666666668e-05, 'epoch': 2.24}\n",
      "{'loss': 0.8246, 'grad_norm': 13.813542366027832, 'learning_rate': 1.2e-05, 'epoch': 2.28}\n",
      "{'loss': 0.9147, 'grad_norm': 9.61353874206543, 'learning_rate': 1.1333333333333334e-05, 'epoch': 2.32}\n",
      "{'loss': 0.7007, 'grad_norm': 10.634170532226562, 'learning_rate': 1.0666666666666667e-05, 'epoch': 2.36}\n",
      "{'loss': 0.7331, 'grad_norm': 8.63021469116211, 'learning_rate': 1e-05, 'epoch': 2.4}\n",
      "{'loss': 0.7192, 'grad_norm': 11.187542915344238, 'learning_rate': 9.333333333333334e-06, 'epoch': 2.44}\n",
      "{'loss': 0.5945, 'grad_norm': 14.229763984680176, 'learning_rate': 8.666666666666668e-06, 'epoch': 2.48}\n",
      "{'loss': 0.5936, 'grad_norm': 8.52040958404541, 'learning_rate': 8.000000000000001e-06, 'epoch': 2.52}\n",
      "{'loss': 0.6189, 'grad_norm': 10.783103942871094, 'learning_rate': 7.333333333333334e-06, 'epoch': 2.56}\n",
      "{'loss': 0.5363, 'grad_norm': 13.263206481933594, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.6}\n",
      "{'loss': 1.0725, 'grad_norm': 16.981788635253906, 'learning_rate': 6e-06, 'epoch': 2.64}\n",
      "{'loss': 0.8021, 'grad_norm': 13.635452270507812, 'learning_rate': 5.333333333333334e-06, 'epoch': 2.68}\n",
      "{'loss': 0.7739, 'grad_norm': 10.481491088867188, 'learning_rate': 4.666666666666667e-06, 'epoch': 2.72}\n",
      "{'loss': 0.7576, 'grad_norm': 14.263216972351074, 'learning_rate': 4.000000000000001e-06, 'epoch': 2.76}\n",
      "{'loss': 0.6624, 'grad_norm': 12.612874031066895, 'learning_rate': 3.3333333333333333e-06, 'epoch': 2.8}\n",
      "{'loss': 0.3809, 'grad_norm': 8.47249984741211, 'learning_rate': 2.666666666666667e-06, 'epoch': 2.84}\n",
      "{'loss': 0.4774, 'grad_norm': 17.498754501342773, 'learning_rate': 2.0000000000000003e-06, 'epoch': 2.88}\n",
      "{'loss': 0.6518, 'grad_norm': 12.373422622680664, 'learning_rate': 1.3333333333333334e-06, 'epoch': 2.92}\n",
      "{'loss': 0.857, 'grad_norm': 13.308266639709473, 'learning_rate': 6.666666666666667e-07, 'epoch': 2.96}\n",
      "{'loss': 0.6366, 'grad_norm': 7.495317459106445, 'learning_rate': 0.0, 'epoch': 3.0}\n",
      "{'train_runtime': 9375.005, 'train_samples_per_second': 0.32, 'train_steps_per_second': 0.04, 'train_loss': 1.0685885219573974, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=1.0685885219573974, metrics={'train_runtime': 9375.005, 'train_samples_per_second': 0.32, 'train_steps_per_second': 0.04, 'total_flos': 789354427392000.0, 'train_loss': 1.0685885219573974, 'epoch': 3.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd995b75521543d8b2b877b731fc67cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0107749700546265,\n",
       " 'eval_accuracy': 0.598,\n",
       " 'eval_runtime': 1397.7161,\n",
       " 'eval_samples_per_second': 0.715,\n",
       " 'eval_steps_per_second': 0.089,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5539393424987793,\n",
       " 'eval_accuracy': 0.817,\n",
       " 'eval_runtime': 899.1812,\n",
       " 'eval_samples_per_second': 1.112,\n",
       " 'eval_steps_per_second': 0.139,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=small_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained('./fine-tuned-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load the fine-tuned model\n",
    "#model = AutoModelForSequenceClassification.from_pretrained('./fine-tuned-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()\n",
    "model.push_to_hub(\"HuggingfaceUsername/yourModelName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 4, 'text': 'Officially my favorite steakhouse hands down!  As if Vegas doesn\\'t have enough to write about, this little gem is in one of the remaining standouts of what some call \\\\\"Old Vegas\\\\\".  The meal got off to a great start at the bar as we waited for our table.  The service was fast, the drinks were well made and naturally they were top shelf.  I was particularly pleased with the professional look and feel of the place.  Its very old school, mafioso, dark, white linen, with the sounds of clinking wine glasses and lively conversation in the background.  \\\\n\\\\nThe food:  Excellent!  Your steak is served as intended, well aged beef cooked to order on a hot plate...nothing else!  Fantastic.  The sides are of sharable portions so agree on one for every 2 or 3 people unless you plan on toting a box of leftovers around Vegas.  The mac and cheese is perfect as is the smooth and creamy lobster bisque.  The other members in my party had several cuts of meat and one had a chicken dish...my sincerest apologies for not having info on those.  Fact is, I wanted every square inch of space in my belly for the rib eye on my plate.  Like sooo many other reviews about this place, it was melt in your mouth good.  We also ordered a chocolate gnash desert that could only be made better by eating it off of your favorite super models body, otherwise it was absolute perfection.  \\\\n\\\\nService was superb.  Our waiter was attentive, informative and practiced.  He was professional and friendly.  Over all a fantastic experience.  I will definitely be returning.  Highly recommend this location to anyone.  You will not be disappointed.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-1.7920, -1.4629, -1.2584,  0.7438,  3.3312]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "random_sample = dataset['train'][random.randint(0, len(dataset['train']) - 1)]\n",
    "print(random_sample)\n",
    "tt=tokenizer(random_sample[\"text\"],return_tensors=\"pt\", padding=True, truncation=True)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs=model(**tt)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for random sample: 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = F.softmax(outputs.logits, dim=-1)\n",
    "predictions\n",
    "\n",
    "print(\"Prediction for random sample:\" , (np.argmax(predictions)).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEFT (Parameter Efficient Fine-Tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32, #RANK\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRINT the number of trainable paraemters\n",
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params=0\n",
    "    all_model_params=0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        # If parameter isn't frozen\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model\\n parameters:{trainable_model_params}\\n all model parameters {all_model_params}\\n percentrage of trainable model: {trainable_model_params/all_model_params*100}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "original_model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model\n",
      " parameters:1183493\n",
      " all model parameters 109497610\n",
      " percentrage of trainable model: 1.0808391160318476\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(original_model, lora_config)\n",
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_training_args = TrainingArguments(\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate= 1e-3,#higher learning rate than full fine-tuning\n",
    "    num_train_epochs=3, #increase for more accuracy\n",
    "    logging_steps=5,\n",
    "    report_to = \"none\",\n",
    "    output_dir=\"test_trainer\",\n",
    ")\n",
    "\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2c057022c44f4d89f05636c8745e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7837, 'grad_norm': 8.398237228393555, 'learning_rate': 0.0009866666666666667, 'epoch': 0.04}\n",
      "{'loss': 1.7265, 'grad_norm': 9.236401557922363, 'learning_rate': 0.0009733333333333334, 'epoch': 0.08}\n",
      "{'loss': 1.6929, 'grad_norm': 8.746582984924316, 'learning_rate': 0.00096, 'epoch': 0.12}\n",
      "{'loss': 1.6141, 'grad_norm': 4.345432758331299, 'learning_rate': 0.0009466666666666667, 'epoch': 0.16}\n",
      "{'loss': 1.6893, 'grad_norm': 4.96002197265625, 'learning_rate': 0.0009333333333333333, 'epoch': 0.2}\n",
      "{'loss': 1.6129, 'grad_norm': 5.919672966003418, 'learning_rate': 0.00092, 'epoch': 0.24}\n",
      "{'loss': 1.5789, 'grad_norm': 8.735934257507324, 'learning_rate': 0.0009066666666666666, 'epoch': 0.28}\n",
      "{'loss': 1.4992, 'grad_norm': 9.10274887084961, 'learning_rate': 0.0008933333333333333, 'epoch': 0.32}\n",
      "{'loss': 1.3245, 'grad_norm': 3.858703136444092, 'learning_rate': 0.00088, 'epoch': 0.36}\n",
      "{'loss': 1.2578, 'grad_norm': 4.778931617736816, 'learning_rate': 0.0008666666666666667, 'epoch': 0.4}\n",
      "{'loss': 1.4376, 'grad_norm': 6.073555946350098, 'learning_rate': 0.0008533333333333334, 'epoch': 0.44}\n",
      "{'loss': 1.3375, 'grad_norm': 3.6659531593322754, 'learning_rate': 0.00084, 'epoch': 0.48}\n",
      "{'loss': 1.4277, 'grad_norm': 4.581487655639648, 'learning_rate': 0.0008266666666666666, 'epoch': 0.52}\n",
      "{'loss': 1.2495, 'grad_norm': 6.431841850280762, 'learning_rate': 0.0008133333333333333, 'epoch': 0.56}\n",
      "{'loss': 1.2004, 'grad_norm': 6.578254222869873, 'learning_rate': 0.0008, 'epoch': 0.6}\n",
      "{'loss': 1.4071, 'grad_norm': 7.837015628814697, 'learning_rate': 0.0007866666666666666, 'epoch': 0.64}\n",
      "{'loss': 1.1871, 'grad_norm': 6.028748035430908, 'learning_rate': 0.0007733333333333333, 'epoch': 0.68}\n",
      "{'loss': 1.1072, 'grad_norm': 6.331672191619873, 'learning_rate': 0.00076, 'epoch': 0.72}\n",
      "{'loss': 1.2046, 'grad_norm': 6.086632251739502, 'learning_rate': 0.0007466666666666667, 'epoch': 0.76}\n",
      "{'loss': 1.2047, 'grad_norm': 4.762339115142822, 'learning_rate': 0.0007333333333333333, 'epoch': 0.8}\n",
      "{'loss': 1.1978, 'grad_norm': 5.682645797729492, 'learning_rate': 0.0007199999999999999, 'epoch': 0.84}\n",
      "{'loss': 1.0674, 'grad_norm': 6.9103522300720215, 'learning_rate': 0.0007066666666666666, 'epoch': 0.88}\n",
      "{'loss': 1.0547, 'grad_norm': 9.671396255493164, 'learning_rate': 0.0006933333333333333, 'epoch': 0.92}\n",
      "{'loss': 1.5908, 'grad_norm': 4.480835914611816, 'learning_rate': 0.00068, 'epoch': 0.96}\n",
      "{'loss': 1.2653, 'grad_norm': 3.7076637744903564, 'learning_rate': 0.0006666666666666666, 'epoch': 1.0}\n",
      "{'loss': 0.9769, 'grad_norm': 10.541523933410645, 'learning_rate': 0.0006533333333333333, 'epoch': 1.04}\n",
      "{'loss': 1.2799, 'grad_norm': 4.261051654815674, 'learning_rate': 0.00064, 'epoch': 1.08}\n",
      "{'loss': 1.0619, 'grad_norm': 5.222475528717041, 'learning_rate': 0.0006266666666666668, 'epoch': 1.12}\n",
      "{'loss': 1.229, 'grad_norm': 9.26411247253418, 'learning_rate': 0.0006133333333333334, 'epoch': 1.16}\n",
      "{'loss': 0.9823, 'grad_norm': 3.754549741744995, 'learning_rate': 0.0006, 'epoch': 1.2}\n",
      "{'loss': 1.2518, 'grad_norm': 6.709844589233398, 'learning_rate': 0.0005866666666666667, 'epoch': 1.24}\n",
      "{'loss': 1.0414, 'grad_norm': 5.270525932312012, 'learning_rate': 0.0005733333333333334, 'epoch': 1.28}\n",
      "{'loss': 0.8972, 'grad_norm': 2.9486618041992188, 'learning_rate': 0.0005600000000000001, 'epoch': 1.32}\n",
      "{'loss': 1.0701, 'grad_norm': 6.685080528259277, 'learning_rate': 0.0005466666666666667, 'epoch': 1.36}\n",
      "{'loss': 1.0688, 'grad_norm': 4.187627792358398, 'learning_rate': 0.0005333333333333334, 'epoch': 1.4}\n",
      "{'loss': 1.0444, 'grad_norm': 6.337087154388428, 'learning_rate': 0.0005200000000000001, 'epoch': 1.44}\n",
      "{'loss': 1.2685, 'grad_norm': 6.408426284790039, 'learning_rate': 0.0005066666666666668, 'epoch': 1.48}\n",
      "{'loss': 0.9972, 'grad_norm': 5.575216293334961, 'learning_rate': 0.0004933333333333334, 'epoch': 1.52}\n",
      "{'loss': 1.1203, 'grad_norm': 4.432181358337402, 'learning_rate': 0.00048, 'epoch': 1.56}\n",
      "{'loss': 1.1338, 'grad_norm': 6.926558017730713, 'learning_rate': 0.00046666666666666666, 'epoch': 1.6}\n",
      "{'loss': 0.9514, 'grad_norm': 6.318509101867676, 'learning_rate': 0.0004533333333333333, 'epoch': 1.64}\n",
      "{'loss': 1.1092, 'grad_norm': 4.7602996826171875, 'learning_rate': 0.00044, 'epoch': 1.68}\n",
      "{'loss': 0.9319, 'grad_norm': 5.765594005584717, 'learning_rate': 0.0004266666666666667, 'epoch': 1.72}\n",
      "{'loss': 0.9283, 'grad_norm': 4.595616817474365, 'learning_rate': 0.0004133333333333333, 'epoch': 1.76}\n",
      "{'loss': 1.2703, 'grad_norm': 7.012166500091553, 'learning_rate': 0.0004, 'epoch': 1.8}\n",
      "{'loss': 0.9212, 'grad_norm': 9.464834213256836, 'learning_rate': 0.00038666666666666667, 'epoch': 1.84}\n",
      "{'loss': 0.9376, 'grad_norm': 6.030616283416748, 'learning_rate': 0.0003733333333333334, 'epoch': 1.88}\n",
      "{'loss': 0.8399, 'grad_norm': 5.877108573913574, 'learning_rate': 0.00035999999999999997, 'epoch': 1.92}\n",
      "{'loss': 0.9015, 'grad_norm': 3.059237480163574, 'learning_rate': 0.00034666666666666667, 'epoch': 1.96}\n",
      "{'loss': 0.9153, 'grad_norm': 5.027403354644775, 'learning_rate': 0.0003333333333333333, 'epoch': 2.0}\n",
      "{'loss': 0.8481, 'grad_norm': 5.476929187774658, 'learning_rate': 0.00032, 'epoch': 2.04}\n",
      "{'loss': 0.951, 'grad_norm': 5.28120756149292, 'learning_rate': 0.0003066666666666667, 'epoch': 2.08}\n",
      "{'loss': 0.7312, 'grad_norm': 6.437196731567383, 'learning_rate': 0.0002933333333333333, 'epoch': 2.12}\n",
      "{'loss': 0.7176, 'grad_norm': 5.193145751953125, 'learning_rate': 0.00028000000000000003, 'epoch': 2.16}\n",
      "{'loss': 0.9674, 'grad_norm': 3.456455707550049, 'learning_rate': 0.0002666666666666667, 'epoch': 2.2}\n",
      "{'loss': 0.8701, 'grad_norm': 7.251031875610352, 'learning_rate': 0.0002533333333333334, 'epoch': 2.24}\n",
      "{'loss': 0.8902, 'grad_norm': 6.7978835105896, 'learning_rate': 0.00024, 'epoch': 2.28}\n",
      "{'loss': 0.7869, 'grad_norm': 6.330700874328613, 'learning_rate': 0.00022666666666666666, 'epoch': 2.32}\n",
      "{'loss': 0.9104, 'grad_norm': 7.826595783233643, 'learning_rate': 0.00021333333333333336, 'epoch': 2.36}\n",
      "{'loss': 0.7504, 'grad_norm': 5.4090256690979, 'learning_rate': 0.0002, 'epoch': 2.4}\n",
      "{'loss': 0.8238, 'grad_norm': 7.395232677459717, 'learning_rate': 0.0001866666666666667, 'epoch': 2.44}\n",
      "{'loss': 0.7817, 'grad_norm': 5.111847400665283, 'learning_rate': 0.00017333333333333334, 'epoch': 2.48}\n",
      "{'loss': 0.7956, 'grad_norm': 7.005058765411377, 'learning_rate': 0.00016, 'epoch': 2.52}\n",
      "{'loss': 0.7539, 'grad_norm': 6.681605815887451, 'learning_rate': 0.00014666666666666666, 'epoch': 2.56}\n",
      "{'loss': 0.5775, 'grad_norm': 4.143723964691162, 'learning_rate': 0.00013333333333333334, 'epoch': 2.6}\n",
      "{'loss': 0.9014, 'grad_norm': 3.746448516845703, 'learning_rate': 0.00012, 'epoch': 2.64}\n",
      "{'loss': 0.9681, 'grad_norm': 8.397133827209473, 'learning_rate': 0.00010666666666666668, 'epoch': 2.68}\n",
      "{'loss': 0.862, 'grad_norm': 3.673816680908203, 'learning_rate': 9.333333333333334e-05, 'epoch': 2.72}\n",
      "{'loss': 0.7877, 'grad_norm': 6.838576316833496, 'learning_rate': 8e-05, 'epoch': 2.76}\n",
      "{'loss': 0.8199, 'grad_norm': 6.279844284057617, 'learning_rate': 6.666666666666667e-05, 'epoch': 2.8}\n",
      "{'loss': 0.5953, 'grad_norm': 5.735316753387451, 'learning_rate': 5.333333333333334e-05, 'epoch': 2.84}\n",
      "{'loss': 0.6967, 'grad_norm': 9.59412956237793, 'learning_rate': 4e-05, 'epoch': 2.88}\n",
      "{'loss': 0.8474, 'grad_norm': 8.7481107711792, 'learning_rate': 2.666666666666667e-05, 'epoch': 2.92}\n",
      "{'loss': 0.9971, 'grad_norm': 5.901743412017822, 'learning_rate': 1.3333333333333335e-05, 'epoch': 2.96}\n",
      "{'loss': 0.8021, 'grad_norm': 3.3042120933532715, 'learning_rate': 0.0, 'epoch': 3.0}\n",
      "{'train_runtime': 5904.4317, 'train_samples_per_second': 0.508, 'train_steps_per_second': 0.064, 'train_loss': 1.0837730503082275, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=1.0837730503082275, metrics={'train_runtime': 5904.4317, 'train_samples_per_second': 0.508, 'train_steps_per_second': 0.064, 'total_flos': 800261498880000.0, 'train_loss': 1.0837730503082275, 'epoch': 3.0})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the LoRa fine-tuned model\n",
    "peft_model.save_pretrained('./LoRa-fine-tuned-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdf8f0df22e4fa5ba4d45ecd8ad5425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0099170207977295,\n",
       " 'eval_accuracy': 0.565,\n",
       " 'eval_runtime': 899.0478,\n",
       " 'eval_samples_per_second': 1.112,\n",
       " 'eval_steps_per_second': 0.139,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer.evaluate(eval_dataset=small_eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QLoRa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
